
TODO:

Merge no trunk:                
    -Pequeno refatoramento do TSC segundo os emails:
        - Fazer no trunk e depois no branch
    -Colocar o ctti no trunk e os dummys nos config.h
    -config.h separados para a arch e mach: 
        - Fazer no trunk e depois no branch
    -passar a mach epossoc e as mod no mips32 p/ o trunk
    -Mover código do bootloader para um lgar melhor
    
Refatorar algumas coisas:
    - coregen
         - cores tem que gerados de acordo com o device utilziado
         - incompatibiliades no gerador de clock
    - algums tipos de shared io node não vai rolar pois cada nodo de CPU vai ter uma porrada de coisas que pode gerar incompatibilidades
        - um "Zynq node" teria uma porrada de coisa
    - shared "external memory node" também não rola pelo mesmo motivo (eg.: zynq node vem com seu próprio controlador)
    - por isso deve-se criar várias machines: "epossoc_zynq", "epossoc_leon2", "epossoc_axi4basic", "epossoc_wishbonebasic"
         -a única coisa que elas compartilham é o acesso a NoC
         -as machines "epossoc_*basic" poderiam ser compartilhas por várias arquiteturas, pois podemos usar um nodo comum no caso
          de softcores mais simples e maleáveis, como o plasma e o aeMB
         -as machines "epossoc_*basic" não terão mais acesso à memória externa, isso fica limitado às machines com controlador já embutido
         -no final das contas, não há memória compartilhada entre os nodos
               -memória compartilhas apenas atrvés de shared objects do tipo "Memory" (explicados mais adiante)
         -talvez um "shared_io_node" pode existir para periféricos simples que não precisem de interrupção, como a UART que seria usada para
          carregar a aplicação em diferentes nodos.

Jogar init dos agents para aplicação

Implementar objetos compartilhados (ver descrição detalhada no final)

Implementar a plataforma AUTO mencionada mais pra frente nos Makefiles
    -init dos agents em um .cc separado para que o gerador da plataforma possa utiliza-lo
    -criar vários templates da plataforma: usando um router, 2x2, 3x3, etc
    -em cada template, é instancia um cpu_node
    -o restante das portas da NoC são conectadas em nodos 'Dummy', que apenas retorman erros quando recebem mensagens
            -cada instancia tem um nome conhecido no template: Dummy_X00_Y00_NN, Dummy_X00_Y00_NE, ..., Dummy_X99_Y99_NW
    -o "gerador" apenas roda o init dos agents, descobre os nodos necessários, faz a locação na NoC, e substitui
     no template das plataforma os respectivos nodos dummy pelos gerados pelo Catapult
   -o suporte a multiplos cpu_nodes poderia ser implementado da seguinte forma por ex: 
    make APP="app1, app2" ARCH="arch1, arch2" MACH=".." PLATFORM=auto TARGET="ml605"
        - pra cada possível configuração, deve haver um template que suporte combinações dos nodos instanciados
            - ex.: não é possível instanciar dois nodos que usem DDR3, por exemplo
    -a forma como é feito o carregamento da aplicação deve ser estudada com mais calma
        -eg.: o shared_io/uart mencionado anteriormente

Atualizar o tutorial da dissertação para a nova estrutura e com uma parte envolvendo síntese
    - Fazer versão em inglês na wiki
    - Adicionar outro case com um pipeline mais complexo

Migrar do AXI4 para o wishbone. Flexibilizar o barramento tando na plataforma física quanto virtual

Suportar EPOS@Microblaze (usando o aeMB 2)

Suportar EPOS@SparcV8 (usando Leon 2)

Suportar EPOS@ARM (usando Zynk)

Otimizar o comp. manager e resolver o problema com os deadlocks (ver descrição abaixo)

Resolver bug no Component_Manager
    - Quando usando a plataforma física, tem que chamr um CPU::int_enable() no inicio da main

Otimizar o rtsnoc_to_achannel.v
    - Da pra diminuir em 1 ciclo no tx e no rx
    - Diminuir o numero de registradores usados

Otimizar desempenho para componentes com requisitos de throughput
    - Implementar um objeto compartilhado especial chamado 'Memory<..>' que será usado
      para ter acesso a memória compartilhada entre componentes e define algum esquema de DMA

Implementar modelo funcional do EPOS
    - Basicamente compilar o EPOS todos com um novo mediador da CPU que faz a ponte com o SystemC
    - Leituras/escritas no addr. space de dispositivos devem ser feitas sempre via CPU::in/out
        - Verificar se isso não adiciona overhead no sw final
    - Sincronização com o kernel SystemC acontece no CPU::in/out e no disparo de interrupções
    - EPOS roda dentro de um pthread e o kernel systemC em outra
        - A pthread do EPOS começa a chamar o EPOS pelos inits (instancia os objetos de inicialização na ordem correta)
        - CPU::switch_context simula a troca de contexto entre as threads usando set_jump/long_jump (ver 1º trabalho de SO1)
    - Então, no systemc, implementar a classe Untimed::mips32 que apenas:
        - "instancia o EPOS" dentro de uma pthread
        - mantem a informação do estado da CPU (e.g. int enabled/disabled)
        - gera o sinal para chamar o handler
        - gera as transações no barramento
        - para minimizar as modificações, os devices de memoria continuam existindo no modelo funcional, apenas não serão usados 

Tratamento da semântica e da conversão de tipos de dados entre hardware e software usando o Serializer
    - Criar int8, uint8, int16, int32, que no SW mapeia pro tipo nativo e no hw mapeia pra tipo ac_int ou sc_int
	- Se a ISA que o software roda é little endian, então o HW gerado também tem que ser.

Ajustar os include paths e trocar todos os "" por <> 
    - Obs.: houve problemas com a definição dos include paths no Catapult
    
Mexer nos makefiles para paralelizar os processos de compilação/síntese

Novos makefiles
    - ARCH define apenas a arquitetura do processador = mips32,mb32,arm7, etc
    - MACH define a 'machine', em HW define qual 'proc_io_node' será usado
    - INTERCONNECT define se o interconnect primário será NoC ou barramento
        - em hw, há uma pasta para cada combinação valida de MACH e INTERCONNECT
    - DEVICE define o dispositivo final (eg. spartan3, ml605)
    - PLATFORM define uma instancia da plataforma: como os nodos de hw e sw estão conectados na NoC e no barramento
        - em hw, uma pasta para cada combinação válida de MACH, PLATFORM, DEVICE 
        - criar uma platform AUTO, que seria uma plataforma gerada automaticamente segundo as conf.
          usadas para MACH, INTERCONNECT e DEVICE, e também segundo os componentes em hardware que devem
          ser instanciados. Isso significa gerar automaticamente, por exemplo, a tabela de recursos e a 
          lista de componentes que devem ser inicializados no comp. manager em SW.
              - DEVICE e INTERCONNECT só devem ser definidos se a PLATFORM=AUTO
    - makefiles mais integrados: 
         make MACH=.. ARCH=.. PLATFORM=.. APPLICATION=.. vplat_untimed
            - compila o Epos e inicia a plataforma virtual untimed
         make MACH=.. ARCH=.. PLATFORM=.. APPLICATION=.. functional
            - compila tudo e um unido modelo funcional e roda. 
               Tem que implementar um modelo funcional do EPOS e integrar com o kernel SystemC
         make MACH=.. ARCH=.. PLATFORM=.. APPLICATION=.. vplat_timed
            - compila o Epos e inicia a plataforma virtual temporizada
         make MACH=.. ARCH=.. PLATFORM=.. APPLICATION=.. phy
            - compila o Epos e sintetiza o hw físico
         make MACH=.. ARCH=.. PLATFORM=.. APPLICATION=.. phy_bitstream
            - envia o bitstream
         make MACH=.. ARCH=.. PLATFORM=.. APPLICATION=.. phy_upload
            - faz upload do sw

Otimizar a plataforma cycle-acc
    - Desempenho
    - Accuracy na comunicação SW->HW->SW 

Substituir Maybe<T> por Option<T> ou Safe_Ptr<T> ou whatever
    
              
    
    
SOBRE OBJETOS COMPARTILHADOS/SINGLETONS:

Não tem mais o trait 'singleton'. Os objetos podem ser tanto locais
quanto compartilhados.Usar templates para distinguir:
   'Add add;' -> declara um objeto 'local'
   'Add<2> add;' -> declara um objeto compartilhado

Talvez usar um template separato pra objetos compartilhados:
    'Shared<2, Add>' add;
    
Não usar mais herança para os agents e serializer.
    - Agent instancia o componente e o serializer
    - Todo componente recebe no construtor uma referencia para o seua "Parent"
    - Através dessa referencia tem-se acesso ao serializer e os canais de IO no caso dos componentes em HW
    - Eliminamos os Serializer redundantes. Componentes compostos passam a usar o mesmo buffer
                         

Proxy/Agents diferentes dependendo do tipo do objeto
    - Quando for local e estiver no mesmo domínio do pai: sem treta
    - Quando for local e estiver em domínio diferente do pai:
        - Comm. SW->HW: comp. manager sabe onde estão os 'objetos livres'
                        em HW e aloca um específico
        - Comm. HW->SW: chamadas enviadas sempre sem ID, quando o comp. manager
                        recebe uma, ele escolhe um agent livre e já deixa
                        alocado para aquele determinado endereço físico
    - Quando for compartilhado: sempre mapeado para um proxy, independente do domínio
        - Esquema mais parecido com o atual, o id é usado para obter o endereço
          físico de uma tabela estática
            - separar as tabelas por platforma??
        - Tratamento de concorrência: se durante a execução de uma chamada um agent
          receber um pacote referente a outra chamada enquanto espera, por exemplo,
          por dados da chamada atual, ele joga fora o pacote recebido e notifica a
          origem com um WAIT. A origem deve bloquear até receber um OK do agent. A
          chamada é então recebida. O agent deve manter um lista dos proxys que estão
          esperando para poder notifica-los   
    - Desaparece o array medonho que é passado para os objetos com os ids de toda a hierarquia               


SOBRE O PROBLEMA DOS DEADLOCKS/THREADs:

O que acontece: um proxy, sendo chamado por um componente que está dentro de um agent,
                dentro do tratador de interrupções, vai escrever um pacote na NoC e não
                consegue porque o buffer da NoC tá cheio, ele então trava no 'while(noc.wait)'
                dentro do tratador, travando tudo quando houver outros caras dentro do tratador seriam
                os responsáveis por esvaziar esse buffer da NoC. Deadlock.

Solução: voltar ao esquema anterior e usar thread. Pelo menos uma thread só para tratar req. de chamada em SW
         o tratamento das msg contendo respostas pode continuar dentro do tratador.
         
Implementação atual: problema amenizado com o comp manager parcialmente em hw                   

